{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Applied Deep Learning Tutorial \ncontact: Mark.schutera@kit.edu\n# Deep Learning Foundations\n\n## Introduction\nIn this tutorial, you will attempt to get a first understanding of neural networks and the tensorflow library. You will get an understanding of backpropagation, convolutional layers, fully connected layers, activation functions, loss functions, and bring all this together into your first neural network architecture.\n\n<img src=\"graphics/set_sails.jpg\" width=\"700\"><br>\n<center> Fig. 1: Setting sails for the deep learning journey. Image from [pixabay](https://pixabay.com/de/photos/) </center>\n\n","metadata":{}},{"cell_type":"markdown","source":"## Back Propagation\n\nBackpropagation is the central part of iterative optimization. The backpropagation utilizes the derivative of each unit in the neural network starting with the determined error resulting from the loss function. With the chain rule the various units are connected to obtain the derivatives of the loss function through all layers. The resulting matrix shows you how each weight effects the output and its error. Thus, aiming to minimize the error the derivatives tell you in which direction to update the associated weights.\n\n\nDefine an input vector x with two entries valued (0.2 and 0.4) and a fully connected weight matrix W with two units. The groundtruth should be defined as 1.\n\n\\begin{align}\n\tx =\\begin{bmatrix}\n\t0.2 \\\\ 0.4 \n\t\\end{bmatrix}\n\\end{align}\t\n\n\\begin{align}\n\ty = 1\n\\end{align}\t","metadata":{}},{"cell_type":"code","source":"# We will first do some experiments in numpy, no worries there will be enough tensorflow soon.\nimport numpy as np\n\nx = np.array([[0.2], [2]])\nW = np.array([[-0.3, 0.8]])\ny = 1\n","metadata":{"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Next we need to define our architecture to reach the prediction of our one unit neural network, we split the equation in two functions so we can define the derivates partially in the next step:\n\n\\begin{align}\n\t f(x,W)= || W*x ||^2.\n\\end{align}","metadata":{}},{"cell_type":"code","source":"def multiplication(W,x):\n    q = np.dot(W,x)\n    print(q)\n    return q\n\ndef prediction(q):\n    f_1 = np.multiply(q,q)\n    print(f_1)\n    y_pred = np.sum(f_1)\n   \n    return y_pred","metadata":{"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"To calculate the error we need to specify a loss function or objective function and our weight update step:","metadata":{}},{"cell_type":"code","source":"def update (W, grad_W, learning_rate):\n    W = W + grad_W * learning_rate\n    return W","metadata":{"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def prediction_loss(y_pred, y):\n    #loss: L = Dy^2 -> Deriv.: dL/dy = -2 Dy  (Dy = y - y_pred = error)\n    error = y_pred - y\n    loss = np.multiply(error,error)\n    return loss","metadata":{"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Now it is time to determine the partial derivatives of our neural network. We aim to determine the gradient of our function \n$f(x,W)$ dependent from the input values of our network $x$, and the networks parameters $W$.\n\n\\begin{align}\n\t\\frac{\\partial f(x,W)}{\\partial W}\n\\end{align}\n\n\\begin{align}\n    \\frac{\\partial f(x,W)}{\\partial x}\n\\end{align}\n\nBy using the chain rule we can easily propagate the error through the local derivatives at each operation and unit.\n\nThe derivative of the last stage of our unit can be written as: \n\\begin{align}\n\tf(q)= ||q||^2 = q_{1}^2+...+q_{n}^2, \\frac{\\partial f(q)}{\\partial q} = 2*q_{i}.\n\\end{align}\n\nFor the next node we have two variable inputs and so we have to calculate the local derivatives with respect to both $W$, since this is where we can adjust the weights.\n\\begin{align}\n\tq = W*x\t\n\\end{align}\n\n\\begin{align}\n    \\frac{\\partial q_{k}}{\\partial W_{i,j}}=x\n\\end{align}\n\nWith the chain rule, we can now backpropagate the error to those weights:\n\n\\begin{align}\n    \\frac{\\partial f(x,W)}{\\partial W} = \\frac{\\partial f(q)}{\\partial q} * \\frac{\\partial q}{\\partial W} = 2*q*x^{T}\n\\end{align}\n\n","metadata":{}},{"cell_type":"code","source":"# Starting with the loss function\ndef gradient_loss(y_pred, y):\n    grad_loss = - (y_pred - y) * 2\n    return grad_loss\n\n# Over the square operator\ndef gradient_prediction (q, grad_loss):\n    # dL/dq = dL/dy * dy/dq = ... 2 * q\n    grad_q = grad_loss * 2 * q\n    return grad_q\n\n# Finally to the multiplication of our inputs\ndef gradient_multiplication (x, grad_q):\n    # dL/dx = dL//dq * dq/dw = dL/dq * x\n    if len(x) == 1:\n        grad_W = grad_q * x\n    else:\n        grad_W = grad_q * np.transpose(x)\n    return grad_W","metadata":{"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Finally we bring everything together in our iterative weight update process, in our optimization routine for our neural network.","metadata":{}},{"cell_type":"code","source":"learning_rate = 1e-2\n\nweightlist1 = []\nweightlist2 = []\npredictionlist = []\ngroundtruthlist = []\n\nfor t in range(10):\n    \n    weightlist1.append(W[0][0])\n    weightlist2.append(W[0][1])\n    \n    # Forward pass\n    q = multiplication(W,x)\n    y_pred = prediction(q)\n    loss = prediction_loss(y_pred,y)\n    print(\"Training loss: \", loss)\n    \n    # Backpropagation\n    grad_loss = gradient_loss(y_pred, y)\n    grad_q = gradient_prediction (q, grad_loss)\n    grad_W = gradient_multiplication (x, grad_q)\n    W = update (W, grad_W, learning_rate)\n    predictionlist.append(y_pred)\n    groundtruthlist.append(y)\n    print(\"Current prediction: \", y_pred)","metadata":{"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"[[1.54]]\n[[2.3716]]\nTraining loss:  1.8812865599999997\nCurrent prediction:  2.3716\n[[1.19865814]]\n[[1.43678133]]\nTraining loss:  0.19077793096573217\nCurrent prediction:  1.4367813308347006\n[[1.11405222]]\n[[1.24111234]]\nTraining loss:  0.05813516022627628\nCurrent prediction:  1.2411123394318015\n[[1.07064456]]\n[[1.14627977]]\nTraining loss:  0.021397771751449256\nCurrent prediction:  1.14627977218826\n[[1.04533579]]\n[[1.09272692]]\nTraining loss:  0.00859828235134978\nCurrent prediction:  1.0927269235516297\n[[1.02967178]]\n[[1.06022398]]\nTraining loss:  0.003626927562396606\nCurrent prediction:  1.0602239783009775\n[[1.01965082]]\n[[1.03968779]]\nTraining loss:  0.0015751203015956998\nCurrent prediction:  1.0396877852946684\n[[1.01311124]]\n[[1.02639438]]\nTraining loss:  0.0006966633103661769\nCurrent prediction:  1.0263943802800175\n[[1.00878998]]\n[[1.01765723]]\nTraining loss:  0.0003117777091850404\nCurrent prediction:  1.0176572282418572\n[[1.00591149]]\n[[1.01185793]]\nTraining loss:  0.00014061053282360107\nCurrent prediction:  1.0118579312202256\n","output_type":"stream"}]},{"cell_type":"code","source":"# How do the weights change with respect to the given input? Elaborate?\n\nimport matplotlib.pyplot as plt\nplt.plot(weightlist1, weightlist2, 'o-m')\nplt.xlabel('Weight 1')\nplt.ylabel('Weight 2')\nplt.show()","metadata":{"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"plt.plot(predictionlist, groundtruthlist, 'o-m')\nplt.xlabel('Prediction')\nplt.ylabel('Groundtruth')\nplt.show()","metadata":{"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"# TensorFlow bring it on!\nNow we are going to get our hands dirty with TensorFlow, where most of the hard work is already done for you. This way we can finally focus on \"adding layers\" and \"going deeper\".\n\n## Optimization\nFirst we concentrate on optimization, this is basically mirroring what we did with numpy a few cell above. This time we will implement a full neural network unit, including an activation function and also we are adding a third input, introducing a bias for the unit.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\n\n# For reproducability\nnp.random.seed(2)","metadata":{"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2022-11-05 10:57:29.466310: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2022-11-05 10:57:29.466380: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Neural Network architecture\nn_input = 3\nn_output = 1\nn_units = 1\n\n# Training parameters\nn_updates = 10\n\n\n# Define graph / network\nweights = {\n    'h1': tf.Variable(np.reshape([np.float32(2.0), np.float32(2.0), np.float32(2.0)], (3, 1))),\n    # 'h1': tf.Variable(tf.random_normal([n_input, n_units])),\n}\n\nbiases = {\n    'b1': tf.Variable(np.reshape([np.float32(4.0)], (1, 1))),\n    # 'b1': tf.Variable(tf.random_normal([n_units])),\n}\n\n# This is where we design our unit\nclass unit(tf.keras.Model):\n    def __init__(self, c_weights, c_biases):\n        super(unit, self).__init__(name='')\n        self.c_weights = c_weights\n        self.c_biases = c_biases\n\n    def call(self, x0):\n        # unit / neuron structure\n        layer_1 = tf.add(tf.matmul(tf.cast(x0, tf.float32), self.c_weights['h1']), self.c_biases['b1'])\n        # activation function\n        y_pred = tf.nn.relu(layer_1)\n        return y_pred\n\n\n# Input\nx = tf.Variable(np.reshape([1.0, 1.0, 3.0], (1, 3)))\n# predicted output\ny_pred = unit(weights, biases)\n# Expected output\ny_gt = tf.Variable(np.reshape([10.0], (1, 1)))","metadata":{"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2022-11-05 10:57:31.943201: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n2022-11-05 10:57:31.943297: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n2022-11-05 10:57:31.943350: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jupyter-schutera-2dtutori-2dn-2dto-2dtensorflow-2dpad81giy): /proc/driver/nvidia/version does not exist\n2022-11-05 10:57:31.944057: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","output_type":"stream"}]},{"cell_type":"code","source":"cost = tf.losses.mean_squared_error()\n\n# 1. Stochastic gradient descent\n# opt = tf.train.GradientDescentOptimizer(learning_rate=0.0001)\n\n# 2. Momentum optimizer\n# opt = tf.train.MomentumOptimizer(learning_rate=0.0001, momentum=0.75)\n\n# 3. Adaptive momentum optimizer\n# opt = tf.train.AdamOptimizer(learning_rate=0.0001)\n\n# 4. Adaptive momentum optimizer with adjusted initial learning rate\n# opt = tf.train.AdamOptimizer(learning_rate=0.1)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Open a GradientTape.\nwith tf.GradientTape() as tape:\n    # Forward pass.\n    logits = y_pred(x)\n    # Loss value for this batch.\n    loss_value = cost(y_gt, logits)\n\n# Get gradients of loss wrt the weights.\ngradients = tape.gradient(loss_value, y_pred.trainable_weights)\n\n# Update the weights of the model.\nopt.apply_gradients(zip(gradients, y_pred.trainable_weights))\n\n\nprint(y_pred.trainable_weights)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Try the different backpropagation approaches and see whether you can reproduce the findings presented in the lecture.\n\nNotice the design of tensorflow, which first designs the model and then calls a session where the placeholders are filled and the forward and backward pass are executed.","metadata":{}},{"cell_type":"markdown","source":"## Regularization\nNext we will get an intuition for regularization approaches (Evaluate the different designs 0. to 2.)  Also we are working with the Keras library, which is based on TensorFlow and introduces a more pythonic feeling. Do you have a notion why I would say so?","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\n# Define model\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\n\n  # Design 0. without regularization:\n  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n\n  # Design 1. L2 Parameter norm penalty by kernel regularizer:\n  # tf.keras.layers.Dense(512, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n  # tf.keras.layers.Dense(512, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n  # tf.keras.layers.Dense(512, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n  # tf.keras.layers.Dense(512, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n\n  # Design 2. Dropout:\n  # tf.keras.layers.Dense(512, activation=tf.nn.relu),\n  # tf.keras.layers.Dropout(0.5),\n  # tf.keras.layers.Dense(512, activation=tf.nn.relu),\n  # tf.keras.layers.Dropout(0.5),\n  # tf.keras.layers.Dense(512, activation=tf.nn.relu),\n  # tf.keras.layers.Dropout(0.5),\n  # tf.keras.layers.Dense(512, activation=tf.nn.relu),\n  # tf.keras.layers.Dropout(0.5),\n\n  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define training parameters, feel free to play with the different optimizers as well.\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Load training data (reduce training data to 10k samples)\nmnist = tf.keras.datasets.mnist\n(x_train, y_train), (x_validation, y_validation) = mnist.load_data()\n\n# Normalize input images (comply with activation function)\nx_train, x_validation = x_train / 255.0, x_validation / 255.0","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 3. Augmentation\n# x_train = x_train.reshape(x_train.shape[0], 1, 28, 28)\n# datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n#                                                                 featurewise_center=True,\n#                                                                 featurewise_std_normalization=True,\n#                                                                 rotation_range=20,\n#                                                                 width_shift_range=0.2,\n#                                                                 height_shift_range=0.2,\n#                                                                 horizontal_flip=False\n#                                                                 )\n#\n# for e in range(10):\n#     print('Epoch', e)\n#     batches = 0\n#     for x_batch, y_batch in datagenerator.flow(x_train, y_train, batch_size=32):\n#         model.fit(np.reshape(x_batch, (-1, 28, 28)), y_batch, shuffle=True)\n#         batches += 1\n#         if batches >= len(x_train) / 32:\n#             # we need to break the loop by hand because\n#             # the generator loops indefinitely\n#             break\n\n# 4. Early stopping (usually you should monitor the validation accuracy)\n# es = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n#                                      min_delta=0,\n#                                      patience=1,\n#                                      mode='auto'\n#                                      )\n#\n# Fit model on training data (with callback)\n# model.fit(x_train, \n#          y_train, \n#          epochs=10, \n#          shuffle=True, \n#          callbacks=[es],\n#          validation_data=(x_validation, y_validation)\n#         )\n\n# Fit model on training data (without regularization)\nmodel.fit(x_train, y_train, epochs=10, shuffle=True)\n\n# Evaluate performance on validation set\n_, validation_acc = model.evaluate(x_validation, y_validation)\nprint('validation accuracy:', validation_acc)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Next steps to take it from here\n\n- Keep in mind that [MNIST](http://yann.lecun.com/exdb/mnist/) is the \"Hello world\" of machine learning, this is the go-to-dataset if you are in need for a toy problem. Most new ideas in machine learning are presented by the aid of MNIST, make sure that you familiarize yourself with the dataset and its characteristics.\n- Try different regularization approaches and their influence.\n- Can you think of a good task to introduce Convolutional Neural Networks, including receptive field, strides, semantic information, and so on? (Send your jupyter notebook to mark.schutera@kit.edu for a chance to earn bonus points).\n","metadata":{}},{"cell_type":"code","source":"#Notes:\n#weights develope linear, ","metadata":{},"execution_count":null,"outputs":[]}]}